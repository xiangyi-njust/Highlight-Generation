{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../../data/BioPubSum/BioPubSum_test_fill_filter.xlsx')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights = df['New_Highlight'].tolist()\n",
    "abstracts = df['Abstract'].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare the chatgpt settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'sk-JO2fqzFAodIez6sGE76f61B7FeDc41E4A83e16574a3e28Ef'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\anaconda3\\envs\\pytorch\\lib\\site-packages\\langchain\\llms\\openai.py:179: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "e:\\software\\anaconda3\\envs\\pytorch\\lib\\site-packages\\langchain\\llms\\openai.py:751: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# llm = OpenAI(model_name='gpt-3.5-turbo-16k',temperature=0)\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-0613', temperature=0, openai_api_base='https://api.aimd5.com/v1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'Extract the main work:{input}\\n'\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = ['input'],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toolong_texts = []\n",
    "\n",
    "def generate(texts, args):\n",
    "    for i in tqdm(range(len(texts))):\n",
    "        text = texts[i]\n",
    "        result = chain.run(text)\n",
    "        # try:\n",
    "        #     result = chain.run(text)\n",
    "        # except Exception as e:\n",
    "        #     toolong_texts.append(text)\n",
    "        #     continue\n",
    "        # args.append(result)\n",
    "        args.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "g_res_1, g_res_2, g_res_3, g_res_4, g_res_5 = [],[],[],[],[]\n",
    "pos = int(len(abstracts)/5)\n",
    "\n",
    "t1 = Thread(target=generate, args=(abstracts[0:pos], g_res_1))\n",
    "t2 = Thread(target=generate, args=(abstracts[pos:pos*2], g_res_2))\n",
    "t3 = Thread(target=generate, args=(abstracts[pos*2:pos*3], g_res_3))\n",
    "t4 = Thread(target=generate, args=(abstracts[pos*3:pos*4], g_res_4))\n",
    "t5 = Thread(target=generate, args=(abstracts[pos*4:], g_res_5))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_highlights = g_res_1 + g_res_2 + g_res_3 + g_res_4 + g_res_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_highlights = []\n",
    "\n",
    "for i in tqdm(range(len(abstracts))):\n",
    "    text = abstracts[i]\n",
    "    result = chain.run(text)\n",
    "    generated_highlights.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generate'] = generated_highlights\n",
    "df.to_excel('raw_prompt/abstract_(5)_bio_filter.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_excel('../../data/AIPubSumm/AIPubSumm_train.xlsx')\n",
    "\n",
    "train_highlights = df_train['New_Highlight'].tolist()\n",
    "train_abstracts = df_train['Abstract'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "input:{input}\\n\n",
    "output:{output}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables= ['input','output'],\n",
    "    template = example_formatter_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    'Refine 4~5 innovative points of the scientific paper\\\n",
    "    abstract provided below in bullet point format without additional explanations.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = 'Refine 4~5 innovative points of the scientific paper\\\n",
    "# abstract provided below in bullet point format without additional explanations.'\n",
    "prefix = instructions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### random sample (pseudo input with demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "for i in range(16):\n",
    "    example = {}\n",
    "    # example['input'] = train_abstracts[i]\n",
    "    example['input'] = 'it just a test sentence'\n",
    "    example['output'] = train_highlights[i]\n",
    "\n",
    "    examples.append(example)\n",
    "\n",
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    # prefix = prefix,\n",
    "    suffix = '\\ninput:{input}\\noutput:',\n",
    "    input_variables = ['input'],\n",
    "    example_separator = '\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recognition accuracy and execution time of a facial expression recognition system are improved in this study. Various techniques are utilized to achieve this improvement. The face detection component is implemented using the Viola-Jones descriptor. The detected face is down-sampled using the Bessel transform to reduce the feature extraction space and improve processing time. Gabor feature extraction techniques are employed to extract thousands of facial features representing various facial deformation patterns. An AdaBoost-based hypothesis is formulated to select a subset of the extracted features to speed up classification. The selected features are then fed into a well-designed 3-layer neural network classifier trained using a back-propagation algorithm. The system is trained and tested using datasets from the JAFFE and Yale facial expression databases. An average recognition rate of 96.83% and 92.22% is achieved in the JAFFE and Yale databases, respectively. The execution time for a 100x100 pixel size is 14.5 ms. The results of the proposed techniques are very encouraging when compared with other methods.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "print(chain.run(abstracts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5/65 [00:34<05:54,  5.90s/it]Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "100%|██████████| 65/65 [16:32<00:00, 15.26s/it]  \n"
     ]
    }
   ],
   "source": [
    "generated_highlights = []\n",
    "\n",
    "for i in tqdm(range(len(abstracts))):\n",
    "    text = abstracts[i]\n",
    "    result = chain.run(text)\n",
    "    generated_highlights.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generate'] = generated_highlights\n",
    "df.to_excel('opendata_result/demonstration/number/abstract_(4)_ai_16shot_pseudo_noInstruct.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "# example = {}\n",
    "\n",
    "# example['input'] = train_abstracts[0]\n",
    "# example['output'] = train_highlights[0]\n",
    "\n",
    "# examples.append(example)\n",
    "\n",
    "for i in range(8):\n",
    "    example = {}\n",
    "    example['input'] = train_abstracts[i]\n",
    "    example['output'] = train_highlights[i]\n",
    "\n",
    "    examples.append(example)\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random average\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# seed: 2020 2021 2022 2023\n",
    "np.random.seed(2023)\n",
    "\n",
    "random_array = np.random.choice(len(train_abstracts), size=6, replace=False)\n",
    "\n",
    "examples = []\n",
    "\n",
    "for i in random_array:\n",
    "    example = {}\n",
    "    example['input'] = train_abstracts[i]\n",
    "    example['output'] = train_highlights[i]\n",
    "\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = prefix,\n",
    "    suffix = '\\ninput:{input}\\noutput:',\n",
    "    input_variables = ['input'],\n",
    "    example_separator = '\\n',\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolong_texts = []\n",
    "\n",
    "def generate(texts, args):\n",
    "    # generate_results = list(args)\n",
    "\n",
    "    for i in tqdm(range(len(texts))):\n",
    "        text = texts[i]\n",
    "        try:\n",
    "            result = chain.run(text)\n",
    "        except Exception as e:\n",
    "            toolong_texts.append(text)\n",
    "            continue\n",
    "        # generate_results.append(result)\n",
    "        args.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "g_res_1, g_res_2, g_res_3, g_res_4, g_res_5 = [],[],[],[],[]\n",
    "\n",
    "pos = int(len(abstracts)/5)\n",
    "\n",
    "t1 = Thread(target=generate, args=(abstracts[0:pos], g_res_1))\n",
    "t2 = Thread(target=generate, args=(abstracts[pos:pos*2], g_res_2))\n",
    "t3 = Thread(target=generate, args=(abstracts[pos*2:pos*3], g_res_3))\n",
    "t4 = Thread(target=generate, args=(abstracts[pos*3:pos*4], g_res_4))\n",
    "t5 = Thread(target=generate, args=(abstracts[pos*4:], g_res_5))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()\n",
    "\n",
    "generated_highlights = g_res_1 + g_res_2 + g_res_3 + g_res_4 + g_res_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way: single thread\n",
    "\n",
    "generated_highlights = []\n",
    "\n",
    "for i in tqdm(range(len(abstracts))):\n",
    "    text = abstracts[i]\n",
    "    result = chain.run(text)\n",
    "    generated_highlights.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generate'] = generated_highlights\n",
    "df.to_excel('opendata_result/demonstration/random/abstract_(4)_ai_6shot_random4.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### clostest example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on rouge metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('opendata_result/demonstration/ai_rouge.json', 'r') as f:\n",
    "    rouge_values = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(180, 0.06924643584521385),\n",
       " (192, 0.062091503267973865),\n",
       " (131, 0.0588235294117647),\n",
       " (60, 0.05842696629213483),\n",
       " (52, 0.056497175141242945)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rouge_values = []\n",
    "\n",
    "for items in rouge_values:\n",
    "    items = [item['rouge-2']['f'] for item in items]\n",
    "    item_dict = {}\n",
    "    for i, item in enumerate(items):\n",
    "        item_dict[i] = item\n",
    "    item_dict = sorted(item_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "    new_rouge_values.append(item_dict)\n",
    "\n",
    "new_rouge_values[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rouge\n",
    "\n",
    "def find_closest_rouge_demo(i,  k=5, reverse=False):\n",
    "    rouge_value = new_rouge_values[i][:k]\n",
    "    max_idxs = [item[0] for item in rouge_value]\n",
    "    \n",
    "    if reverse:\n",
    "        max_idxs.reverse()\n",
    "        \n",
    "    # construct example\n",
    "    examples = []\n",
    "    for idx in max_idxs:\n",
    "        example = {}\n",
    "\n",
    "        example['input'] = train_abstracts[idx]\n",
    "        example['output'] = train_highlights[idx]\n",
    "\n",
    "        examples.append(example)\n",
    "\n",
    "    # construct few_shot_prompt\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        examples = examples,\n",
    "        example_prompt = example_prompt,\n",
    "        prefix = prefix,\n",
    "        suffix = '\\ninput: {input}\\nanswer:',\n",
    "        input_variables = ['input'],\n",
    "        example_separator = '\\n',\n",
    "    )\n",
    "\n",
    "    return few_shot_prompt    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('opendata_result/demonstration/ai_train.json', 'r') as f:\n",
    "    train_embeddings = json.load(f)\n",
    "\n",
    "with open('opendata_result/demonstration/ai_test.json', 'r') as f:\n",
    "    test_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sim(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "\n",
    "    cos_similarity = dot_product / (norm_a * norm_b)\n",
    "\n",
    "    return cos_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_values = []\n",
    "\n",
    "for i, item in enumerate(test_embeddings):\n",
    "    item = np.array(item)\n",
    "    sim_value = {}\n",
    "    for j, test_embed in enumerate(train_embeddings):\n",
    "        test_embed = np.array(test_embed)\n",
    "        sim_value[j] = cal_sim(item, test_embed)\n",
    "    \n",
    "    sim_value = sorted(sim_value.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    sim_values.append(sim_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embedding_demo(i, k=5, reverse=False):\n",
    "    test_sample = abstracts[i]\n",
    "    sim_value = sim_values[i]\n",
    "\n",
    "    max_idxs = [sim_value[j][0] for j in range(k)]\n",
    "\n",
    "    if reverse:\n",
    "        max_idxs.reverse()\n",
    "        \n",
    "    # construct example\n",
    "    examples = []\n",
    "\n",
    "    for idx in max_idxs:\n",
    "        example = {}\n",
    "\n",
    "        example['input'] = train_abstracts[idx]\n",
    "        example['output'] = train_highlights[idx]\n",
    "\n",
    "        examples.append(example)\n",
    "\n",
    "    # construct few_shot_prompt\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        examples = examples,\n",
    "        example_prompt = example_prompt,\n",
    "        prefix = prefix,\n",
    "        suffix = '\\ninput: {input}\\nanswer:',\n",
    "        input_variables = ['input'],\n",
    "        example_separator = '\\n',\n",
    "    )\n",
    "\n",
    "    return few_shot_prompt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [03:48<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "generated_highlights = []\n",
    "\n",
    "for i in tqdm(range(len(abstracts))):\n",
    "    text = abstracts[i]\n",
    "    few_shot_prompt = find_closest_rouge_demo(i, k=6, reverse=True)\n",
    "    # few_shot_prompt = find_closest_embedding_demo(i, k=1)\n",
    "    \n",
    "    chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "    \n",
    "    result = chain.run(text)\n",
    "    generated_highlights.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generate'] = generated_highlights\n",
    "df.to_excel('opendata_result/demonstration/similarity/abstract_(4)_ai_6shot_clostRouge_reverse.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
